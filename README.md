# Voice Prompt Project — Development Plan

## Goal
Build a cross-platform mobile app (“voice coach”) that feeds structured prompts in real time to help the speaker stay on message.  
Core behaviors:
- **Plan sessions** as segments with timing, key points, and prompt styles.  
- **Deliver cues** via tone → TTS (or tone only / TTS only).  
- **Detect gaps** in speech (via VAD/ASR) to avoid talking over.  
- **Optionally** insert context-aware segues generated by an LLM.  

---

## Tech Stack & Architecture

### Framework
- **React Native (bare workflow, not Expo)** for UI, orchestration, and cross-platform portability.
- **Native modules** (Swift / Kotlin) handle **all audio-critical tasks** (low latency, scheduling, VAD).
- **Azure Speech** for cloud ASR and Neural TTS (swap in later).
- **LLM backend** (OpenAI/Azure OpenAI) for optional segue generation.

### Project Structure
```
app/
  src/
    screens/            # UI: ScriptComposer, CadencePlanner, SessionRunner
    components/         # Editors, lists
    lib/
      audio/AudioCoach.ts   # RN → Native bridge
      nlp/segues.ts         # segue generation (future)
      asr/azureSpeech.ts    # streaming ASR glue (future)
      types.ts              # Segment / Policy / Plan types
      store.ts              # Zustand state store
    data/
      sample-session.json   # Demo plan
  ios/AudioCoach/       # Swift native module + bridge
  android/audiocoach/   # Kotlin native module + package
```

### Data Model
```ts
Segment {
  id: string
  title: string
  keyPoints: string[]
  promptType: "topic" | "line"
  promptText?: string
  targetSecs: number
  toleranceSecs?: number
  minGapMs: number
  cueStyle: "tone_then_tts" | "tone_only" | "tts_only"
  priority: number
}

SessionPolicy {
  interruptMode: "none" | "tone_only" | "soft_duck"
  maxRambleSecs: number
  fallbackCueText?: string
  preRollToneMs: number
  asrEnabled: boolean
  ttsVoiceId?: string
}

SessionPlan {
  id: string
  title: string
  segments: Segment[]
  policy: SessionPolicy
}
```

---

## Key Recommendations

### Why React Native (bare)
- Fast cross-platform UI dev.  
- Shared business logic.  
- Native audio modules keep latency tight.  
- Lower cost than fully native builds.

### Where Native Is Mandatory
- **Cue scheduling** — must live in Swift/Kotlin (JS timers drift).  
- **VAD/silence detection** — use WebRTC VAD or platform tools.  
- **Audio routing** — Bluetooth/AirPods, background audio, ducking.  
- **TTS/ASR integration** — start with AVSpeechSynthesizer/Android TTS; later swap to Azure Neural.

### Boundaries
- **True barge-in interruptions** (AI cutting over mid-sentence) aren’t realistic right now.  
- MVP will cue only at **first clean silence ≥ `minGapMs`**.  
- ASR/VAD drift and scheduling must be handled natively to avoid lag.  

---

## Sprint Plan

### Sprint 1 (MVP Core Loop)
- RN UI screens for composing/playing sessions.  
- Native audio engine stubs (tone + basic TTS).  
- JSON import/export of session plans.  
- Press **Start** → hear tone + placeholder spoken prompt after delay.  

### Sprint 2 (Timing & VAD)
- Implement silence detection (WebRTC VAD).  
- Trigger cues only on clean gaps.  
- Add **ramble guard** (targetSecs + tolerance → nudge tone).  

### Sprint 3 (Cloud Services)
- Swap local TTS → **Azure Neural TTS**.  
- Add streaming ASR for more accurate timing + transcript logging.  
- Pass transcript + next segment to LLM for **dynamic segues**.  

---

## Immediate Next Steps
1. **Unzip scaffold** (already provided) into `voicepromptproject`.  
2. Wire native modules into RN project:  
   - iOS: Add Swift files to Xcode target, enable Background Audio.  
   - Android: Register `AudioCoachPackage` in `MainApplication`.  
3. Install deps:  
   ```bash
   npm install zustand uuid
   ```  
4. Run simulator, open `SessionRunner`, press **Start** → should see status events and a test cue.  
5. Commit as initial Git push:  
   ```bash
   git init
   git add .
   git commit -m "Initial scaffold for Voice Prompt Project"
   git remote add origin <your-repo-url>
   git push -u origin main
   ```

---

## Future Enhancements
- Configurable **cue voices** and **pre-roll tone styles**.  
- **Background sessions** (screen off, still running).  
- **Segues trained** on your corpus (brand lexicon, tone).  
- Desktop companion app (Electron) for rehearsal/studio mode.  
